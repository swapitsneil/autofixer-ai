# AutoFixer AI - Autonomous Bug Recovery System

An autonomous system that detects, analyzes, and fixes production bugs using AI agents, workflow orchestration, and automated deployment.

## ğŸ¯ Project Overview

**What is AutoFixer AI?**

AutoFixer AI is an autonomous bug recovery system that demonstrates how AI agents can work together to identify, diagnose, and fix runtime errors in production applications. When a bug occurs, the system automatically analyzes the root cause, generates a fix, reviews it, and deploys the correctionâ€”all within minutes.

**The Real-World Problem**

Production bugs cost time, money, and user trust. Traditional debugging requires:
- Manual investigation by developers
- Time-consuming root cause analysis
- Manual fix creation and testing
- Code review and deployment cycles

AutoFixer AI automates this entire pipeline, reducing recovery time from hours to minutes.

**Why Autonomous Bug Fixing Matters**

- **Speed**: Fixes deploy in ~5 minutes instead of hours
- **Consistency**: AI agents follow systematic analysis patterns
- **24/7 Availability**: Works even when developers are offline
- **Reduced Cognitive Load**: Developers focus on features, not firefighting

## ğŸš€ Screenshots

<img width="2608" height="1528" alt="Image" src="https://github.com/user-attachments/assets/e08ccf25-669c-4989-9704-9482c06685bc" />

vercel - https://autofixer-ai.vercel.app/

## ğŸ—ï¸ Architecture Overview

AutoFixer AI is built as a multi-layer system where each component has a specific responsibility:

### System Components

**1. Next.js Demo Application**
- Production-like web application with intentional bugs
- Error logging to orchestration layer
- Interactive UI for demonstration purposes
- Snippet Fix Demo for capability showcase

**2. Kestra Orchestration**
- Event-driven workflow engine
- Captures production errors via webhooks
- Coordinates the entire fix pipeline
- Validates and enriches incident data

**3. Oumi AI Agents (Reasoning Layer)**
- **Forensics Agent**: Analyzes logs to identify root cause
- **Incident Agent**: Categorizes and prioritizes errors
- **Patch Agent**: Generates minimal, targeted fixes
- **Root Cause Agent**: Deep analysis of error patterns
- **Validation Agent**: Verifies fix correctness

**4. Cline CLI (Autonomous Coding)**
- Applies fixes to source code
- Runs tests to validate changes
- Creates pull requests automatically
- Follows systematic coding practices

**5. CodeRabbit (AI Code Review)**
- Reviews generated fixes
- Provides feedback on code quality
- Approves or requests changes
- Ensures maintainability

**6. Vercel (Deployment)**
- Automated deployment of approved fixes
- Production monitoring and health checks
- Rollback capabilities if issues occur

## ğŸ”„ How the System Works

### Step-by-Step Recovery Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. ERROR   â”‚  Production bug occurs
â”‚   OCCURS    â”‚  in Next.js app
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. LOGS    â”‚  Error captured and
â”‚ CAPTURED &  â”‚  sent to Kestra
â”‚ ORCHESTRATEDâ”‚  workflow engine
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. AI      â”‚  Oumi agents analyze
â”‚  REASONING  â”‚  root cause and
â”‚             â”‚  generate fix
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. FIX     â”‚  Cline applies fix
â”‚  APPLIED    â”‚  to source code
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. CODE    â”‚  CodeRabbit reviews
â”‚   REVIEW    â”‚  and approves fix
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. DEPLOY  â”‚  Vercel deploys
â”‚             â”‚  to production
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Detailed Flow

**Step 1: Error Occurs**
- User encounters a bug in the application
- Application logs error with stack trace
- Error details sent to Kestra webhook

**Step 2: Orchestration**
- Kestra receives the error event
- Validates and enriches incident data
- Triggers appropriate workflow chain
- Routes to AI reasoning layer

**Step 3: AI Analysis**
- Forensics Agent examines logs and code
- Identifies root cause (e.g., undefined variable)
- Patch Agent generates minimal fix
- Validation Agent verifies fix logic

**Step 4: Fix Application**
- Cline receives fix plan
- Applies changes to source code
- Runs automated tests
- Creates pull request

**Step 5: Code Review**
- CodeRabbit reviews the PR
- Checks for code quality and safety
- Provides feedback or approval
- Ensures maintainability standards

**Step 6: Deployment**
- Vercel automatically deploys approved fix
- System health verified
- Monitoring enabled for new version
- Recovery complete (~5 minutes total)

## ğŸ§ª Snippet Fix Demo

### What It Is

The Snippet Fix Demo is a **capability demonstration** that shows how the AI system analyzes and fixes small code snippets. It's designed to give judges and users a hands-on experience with the AI's bug-fixing logic.

### How It Works

**User Input**
- Paste a small buggy code snippet (10-20 lines)
- Click "Analyze & Fix Snippet"
- View detected issues and corrected code

**What Happens Behind the Scenes**

1. **Deterministic Fix Engine**
   - Applies rule-based fixes (e.g., `var` â†’ `let`)
   - Fixes off-by-one errors (`<= length` â†’ `< length`)
   - Adds missing variable declarations
   - Corrects wrong return statements

2. **Validation Gate**
   - Ensures zero undefined identifiers
   - Preserves function names and parameters
   - Rejects unsafe or intent-changing fixes
   - Guarantees syntactic correctness

3. **AI Explanation**
   - Lists accurately detected issues
   - Explains what was fixed and why
   - No hallucinations or false claims

### Important Limitations

**This is NOT a full application fixer.**
- Designed for small snippets only (10-20 lines)
- Limited to common, well-understood bug patterns
- Cannot fix complex logic errors or architectural issues
- Not all code can be safely auto-fixed

**What It Can Fix**
- Missing variable declarations
- Off-by-one loop errors
- Wrong return variables
- Modern JavaScript practices (`var` â†’ `let`)

**What It Cannot Fix**
- Complex algorithmic errors
- Design pattern issues
- Performance problems
- Security vulnerabilities

**Honest Scope**
This is a demonstration of AI-assisted fixing capability, not a universal solution. In production, the full AutoFixer AI system uses more sophisticated analysis, multiple AI agents, and human-in-the-loop review.

## ğŸ›¡ï¸ Safety & Validation

### No Blind AI Fixes

AutoFixer AI does NOT blindly trust AI-generated code. Every fix goes through:

**1. Multi-Agent Validation**
- Multiple AI agents analyze the same problem
- Consensus-based decision making
- Cross-validation of proposed fixes

**2. Systematic Testing**
- Automated tests run on every fix
- Regression testing ensures no new bugs
- Performance impact assessed

**3. Code Review**
- CodeRabbit provides AI code review
- Human-like quality standards
- Maintainability checks

**4. Validation Gate (Snippet Demo)**
- Rejects function name changes
- Prevents parameter modifications
- Blocks unsafe identifier replacement
- Ensures zero undefined variables

### Preventing Hallucinations

**Snippet Demo Safeguards**
- Deterministic fixes applied first
- AI only explains, never generates code
- No false positives in issue detection
- Clear fallback when fixes aren't safe

**Production Pipeline Safeguards**
- Multiple AI agents verify each other
- Systematic testing catches errors
- Code review prevents bad changes
- Rollback capability if issues arise

## âš ï¸ Limitations

### Snippet Fix Demo Limitations

**Designed for Demonstration**
- Limited to 10-20 line snippets
- Only handles common bug patterns
- Cannot fix complex logic errors
- Not a replacement for human developers

**Scope Boundaries**
- No execution of user code
- No complex algorithm fixes
- No architectural refactoring
- No security vulnerability fixes

**When It Won't Work**
- Code with complex dependencies
- Bugs requiring domain knowledge
- Issues needing design changes
- Problems without clear patterns

### System-Wide Limitations

**Not Fully Autonomous (Yet)**
- Requires human oversight for critical changes
- Limited to well-defined error patterns
- Cannot handle novel or complex bugs
- Needs clear error logs to function

**Technical Constraints**
- Depends on quality of error logging
- Requires structured codebase
- Limited by AI model capabilities
- Needs orchestration infrastructure

**Real-World Challenges**
- Not all bugs are auto-fixable
- Some fixes require human judgment
- Complex systems need careful changes
- Production deployment has risks

### Honest Assessment

AutoFixer AI is a **proof-of-concept** demonstrating the potential of autonomous bug fixing. It successfully handles common, well-defined errors but is not a universal solution. The goal is to show what's possible with current AI technology, not to claim perfection.

## ğŸ† Hackathon Context

### AI Usage Policy

This project was developed for an AI hackathon where **LLM usage is allowed and encouraged**. The system demonstrates:

**1. Autonomous AI Agents**
- Multiple AI agents working together
- Systematic reasoning about code
- Collaborative problem-solving

**2. Real-World Engineering**
- Production-grade architecture
- Safety and validation mechanisms
- Systematic testing and deployment

**3. Honest Demonstration**
- Clear scope and limitations
- No overclaiming of capabilities
- Transparent about what works and what doesn't

### What Judges Should Know

**This is Real Engineering**
- Not just a demo or presentation
- Working system with actual components
- Demonstrates production-ready thinking

**Emphasis on Safety**
- Multiple validation layers
- No blind trust in AI
- Human-in-the-loop where needed

**Honest About Limitations**
- Clear about what the system can and cannot do
- No marketing hype or false claims
- Transparent about scope

**Educational Value**
- Shows how AI can augment developers
- Demonstrates systematic debugging
- Illustrates autonomous system design

## ğŸš€ Getting Started

### Prerequisites

- Node.js 18+
- npm or yarn
- Kestra server (localhost:8080)
- Together AI account (for Oumi agents)
- CodeRabbit account (for code review)
- Vercel account (for deployment)

### Installation

```bash
# Clone the repository
git clone <repository-url>
cd autofixer-ai

# Install app dependencies
cd app
npm install
cd ..

# Set up environment variables
cp .env.example .env
# Edit .env with your API keys and configurations
```

### Running the Demo

```bash
# Start the Next.js app
cd app
npm run dev
```

Visit [http://localhost:3000](http://localhost:3000) to see the demo.

### Triggering the Pipeline

**Option 1: Web UI**
- Click "Trigger Random Calc" (20% failure + undefined variable)
- Click "Trigger Guaranteed Bug" (always fails)

**Option 2: API Calls**
```bash
# Calculator endpoint
curl "http://localhost:3000/api/calc?a=5&b=10"

# Guaranteed error endpoint
curl "http://localhost:3000/api/trigger-bug"
```

### Testing the Snippet Fix Demo

1. Open http://localhost:3000
2. Scroll to "Snippet Fix Demo" section
3. Paste a buggy code snippet (10-20 lines)
4. Click "Analyze & Fix Snippet"
5. Review detected issues and corrected code

**Example Input:**
```javascript
function average(numbers) {
  var sum = 0;
  for (var i = 0; i <= numbers.length; i++) {
    sum = sum + numbers[i];
  }
  return sum / count;
}
```

**Expected Output:**
- Detected Issues: Off-by-one error, undefined variable
- Corrected Code: Fixed loop condition, replaced `count` with `numbers.length`

## ğŸ“ Project Structure

```
autofixer-ai/
â”œâ”€â”€ app/                    # Next.js demo application
â”‚   â”œâ”€â”€ pages/             # API routes and UI
â”‚   â”œâ”€â”€ lib/               # Utilities
â”‚   â””â”€â”€ package.json       # Dependencies
â”œâ”€â”€ kestra/                # Workflow orchestration
â”‚   â”œâ”€â”€ workflows/         # Kestra workflow definitions
â”‚   â””â”€â”€ templates/         # Reusable templates
â”œâ”€â”€ agents/                # AI reasoning layer
â”‚   â”œâ”€â”€ forensics_agent.json
â”‚   â”œâ”€â”€ incident_agent.json
â”‚   â”œâ”€â”€ patch_agent.json
â”‚   â”œâ”€â”€ root_cause_agent.json
â”‚   â””â”€â”€ validation_agent.json
â”œâ”€â”€ cline/                 # CLI integration
â”‚   â”œâ”€â”€ prompts/           # AI prompts
â”‚   â””â”€â”€ scripts/           # Automation scripts
â””â”€â”€ docs/                  # Documentation
    â”œâ”€â”€ architecture.md
    â”œâ”€â”€ incident_timeline.md
    â””â”€â”€ fix_summary.txt
```

## ğŸ“– Documentation

- [System Architecture](docs/architecture.md) - Detailed architecture overview
- [Incident Timeline](docs/incident_timeline.md) - Example bug recovery timeline
- [Fix Summary](docs/fix_summary.txt) - Example fix analysis

## ğŸ¤ Contributing

This project was developed for an AI hackathon. For questions or feedback, please reach out to the AutoFixer AI team.

## ğŸ”— Technologies Used

- [Next.js](https://nextjs.org/) - React framework for the demo app
- [Kestra](https://kestra.io/) - Workflow orchestration
- [Oumi](https://github.com/oumigroup/oumi) - AI agent framework
- [Together AI](https://together.ai/) - AI model provider
- [Cline](https://github.com/eline/cline) - Autonomous coding CLI
- [CodeRabbit](https://coderabbit.ai/) - AI code review
- [Vercel](https://vercel.com/) - Deployment platform

## ğŸ™ Acknowledgments

Built for the AI hackathon with a focus on demonstrating real-world autonomous system design, honest capability assessment, and production-ready engineering practices.

---

**AutoFixer AI** - Demonstrating the future of autonomous software development, one bug at a time.
